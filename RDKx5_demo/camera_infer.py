# camera_detect_final.py - å®Œæ•´çš„å®æ—¶æ£€æµ‹è„šæœ¬
#!/usr/bin/env python3
"""
YOLOv11n æ‘„åƒå¤´å®æ—¶æ£€æµ‹ - å®Œæ•´ç‰ˆ
åŒ…å«ï¼šé¢„å¤„ç†ã€BPUæ¨ç†ã€åå¤„ç†ã€NMSã€ç»˜åˆ¶ã€æ˜¾ç¤º
"""
import cv2
import numpy as np
import time
from hobot_dnn import pyeasy_dnn as dnn

class YOLOv11Detector:
    """YOLOv11æ£€æµ‹å™¨ç±»"""
    
    def __init__(self, model_path, conf_thresh=0.3, nms_thresh=0.5,cls_num=80):
        """
        åˆå§‹åŒ–æ£€æµ‹å™¨
        
        Args:
            model_path: binæ¨¡å‹è·¯å¾„
            conf_thresh: ç½®ä¿¡åº¦é˜ˆå€¼ (0.0-1.0)
            nms_thresh: NMSé˜ˆå€¼ (0.0-1.0)
        """
        self.conf_thresh = conf_thresh
        self.nms_thresh = nms_thresh
        self.input_size = 640
        self.reg_max = 16  # DFLçš„æœ€å¤§å›å½’è·ç¦»
        self.strides = [8, 16, 32]  # ä¸‰ä¸ªæ£€æµ‹å¤´çš„stride
        self.cls_num=cls_num
        # åŠ è½½æ¨¡å‹
        models = dnn.load(model_path)
        self.model = models[0]
        print(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ: {model_path}")
        
        # é¢„è®¡ç®—anchor gridï¼ˆåŠ é€Ÿåå¤„ç†ï¼‰
        self._init_anchors()
        
        # COCO 80ç±»ç±»åˆ«åç§°
        self.class_names = [
            'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck',
            'boat', 'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench',
            'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra',
            'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee',
            'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove',
            'skateboard', 'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup',
            'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange',
            'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch',
            'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse',
            'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink',
            'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier',
            'toothbrush'
        ]
        
        # ä¸ºæ¯ä¸ªç±»åˆ«ç”Ÿæˆéšæœºé¢œè‰²
        np.random.seed(42)
        self.colors = np.random.randint(0, 255, size=(len(self.class_names), 3), dtype=int)
    
    def _init_anchors(self):
        """
        é¢„è®¡ç®—anchor grid
        å¯¹äº640x640è¾“å…¥ï¼Œä¸‰ä¸ªæ£€æµ‹å¤´çš„gridå¤§å°ä¸ºï¼š
        - stride=8:  80x80
        - stride=16: 40x40
        - stride=32: 20x20
        """
        self.grids = []
        for stride in self.strides:
            h = w = self.input_size // stride
            # ç”Ÿæˆç½‘æ ¼åæ ‡ (h, w, 2)
            grid_y, grid_x = np.meshgrid(np.arange(h), np.arange(w), indexing='ij')
            grid = np.stack([grid_x, grid_y], axis=-1).reshape(-1, 2)
            self.grids.append(grid)
    
    def bgr_to_nv12(self, img):
        """
        BGRå›¾ç‰‡è½¬NV12æ ¼å¼ + Letterboxç¼©æ”¾
        
        NV12æ ¼å¼è¯´æ˜ï¼š
        - Yå¹³é¢: 640x640 (äº®åº¦)
        - UVå¹³é¢: 320x640 (è‰²åº¦ï¼ŒUå’ŒVäº¤é”™å­˜å‚¨)
        - æ€»å¤§å°: 640x960
        
        Args:
            img: BGRå›¾ç‰‡ (H, W, 3)
        
        Returns:
            nv12: NV12æ•°æ® (960, 640)
            scale: ç¼©æ”¾æ¯”ä¾‹
            pad_left: å·¦è¾¹padding
            pad_top: ä¸Šè¾¹padding
        """
        h, w = img.shape[:2]
        
        # è®¡ç®—ç¼©æ”¾æ¯”ä¾‹ï¼ˆä¿æŒå®½é«˜æ¯”ï¼‰
        scale = min(self.input_size / h, self.input_size / w)
        new_h, new_w = int(h * scale), int(w * scale)
        
        # Letterbox resize
        resized = cv2.resize(img, (new_w, new_h))
        canvas = np.full((self.input_size, self.input_size, 3), 114, dtype=np.uint8)
        top = (self.input_size - new_h) // 2
        left = (self.input_size - new_w) // 2
        canvas[top:top+new_h, left:left+new_w] = resized
        
        # BGR to YUV (I420æ ¼å¼)
        yuv = cv2.cvtColor(canvas, cv2.COLOR_BGR2YUV_I420)
        
        # æå–Yã€Uã€Vå¹³é¢
        y = yuv[:self.input_size, :]
        u = yuv[self.input_size:self.input_size+self.input_size//4, :].reshape(
            self.input_size//2, self.input_size//2)
        v = yuv[self.input_size+self.input_size//4:, :].reshape(
            self.input_size//2, self.input_size//2)
        
        # ç»„è£…NV12 (UVäº¤é”™å­˜å‚¨)
        uv = np.empty((self.input_size//2, self.input_size), dtype=np.uint8)
        uv[:, 0::2] = u
        uv[:, 1::2] = v
        
        nv12 = np.concatenate([y, uv], axis=0)
        
        return nv12, scale, left, top
    
    def dfl_decode(self, bbox_raw):
        """
        DFL (Distribution Focal Loss) è§£ç 
        
        å°†64ç»´çš„åˆ†å¸ƒç‰¹å¾è§£ç ä¸º4ç»´çš„bboxåæ ‡(ltrb)
        
        åŸç†ï¼š
        1. å°†64ç»´reshapeä¸º(4, 16)ï¼Œæ¯ä¸ªæ–¹å‘16ä¸ªbin
        2. å¯¹æ¯ä¸ªæ–¹å‘åšSoftmaxï¼Œå¾—åˆ°æ¦‚ç‡åˆ†å¸ƒ
        3. è®¡ç®—æœŸæœ›å€¼ï¼ˆåŠ æƒæ±‚å’Œï¼‰ä½œä¸ºæœ€ç»ˆè·ç¦»
        
        Args:
            bbox_raw: (N, 64) DFLç‰¹å¾
        
        Returns:
            ltrb: (N, 4) è¾¹ç•Œæ¡†è·ç¦»(left, top, right, bottom)
        """
        # Reshape: (N, 64) -> (N, 4, 16)
        bbox = bbox_raw.reshape(-1, 4, self.reg_max)
        
        # Softmaxå½’ä¸€åŒ–
        bbox_exp = np.exp(bbox - np.max(bbox, axis=-1, keepdims=True))
        bbox_softmax = bbox_exp / np.sum(bbox_exp, axis=-1, keepdims=True)
        
        # è®¡ç®—æœŸæœ›å€¼ (åŠ æƒæ±‚å’Œ)
        weights = np.arange(self.reg_max).reshape(1, 1, -1)
        ltrb = np.sum(bbox_softmax * weights, axis=-1)
        
        return ltrb
    
    def detect(self, img):
        """
        æ‰§è¡Œç›®æ ‡æ£€æµ‹
        
        æµç¨‹ï¼š
        1. é¢„å¤„ç†ï¼šBGR -> NV12
        2. BPUæ¨ç†ï¼šforward
        3. åå¤„ç†ï¼šè§£ç  + NMS
        
        Args:
            img: è¾“å…¥å›¾ç‰‡ (BGRæ ¼å¼)
        
        Returns:
            boxes: æ£€æµ‹æ¡† (N, 4) xyxyæ ¼å¼
            scores: ç½®ä¿¡åº¦ (N,)
            classes: ç±»åˆ«ID (N,)
        """
        orig_h, orig_w = img.shape[:2]
        
        # 1. é¢„å¤„ç†
        nv12, scale, pad_left, pad_top = self.bgr_to_nv12(img)
        
        # 2. BPUæ¨ç†
        outputs = self.model.forward(nv12)
        
        # 3. åå¤„ç†
        boxes, scores, classes = self._postprocess(
            outputs, scale, pad_left, pad_top, orig_w, orig_h
        )
        
        return boxes, scores, classes
    
    def _postprocess(self, outputs, scale, pad_left, pad_top, orig_w, orig_h):
        """
        åå¤„ç†ï¼šè§£ç  + ç­›é€‰ + NMS
        
        è¾“å‡ºæ ¼å¼ï¼š
        - outputs[0-2]: bboxç‰¹å¾ (stride=8/16/32)
        - outputs[3-5]: classåˆ†æ•° (stride=8/16/32)
        
        ä¼˜åŒ–ç­–ç•¥ï¼š
        - åˆ©ç”¨Sigmoidå•è°ƒæ€§ï¼Œå…ˆç­›é€‰å†è®¡ç®—
        - å‡å°‘ä¸å¿…è¦çš„DFLè§£ç 
        """
        all_boxes = []
        all_scores = []
        all_classes = []
        
        # åˆ†ç¦»bboxå’Œclsè¾“å‡º
        bbox_outputs = outputs[:3]
        cls_outputs = outputs[3:]
        
        # éå†ä¸‰ä¸ªæ£€æµ‹å¤´
        for i, (bbox_out, cls_out, grid, stride) in enumerate(
            zip(bbox_outputs, cls_outputs, self.grids, self.strides)):
            
            # è·å–åŸå§‹è¾“å‡º (é‡åŒ–åçš„int16æ•°æ®ä¼šè‡ªåŠ¨è½¬ä¸ºfloat32)
            bbox_feat = bbox_out.buffer.reshape(-1, 64)   # (H*W, 64)
            cls_feat = cls_out.buffer.reshape(-1, self.cls_num) #(-1, 80)         # (H*W, 80)
            
            # ====== ä¼˜åŒ–ï¼šå…ˆç­›é€‰å†è®¡ç®— ======
            # Sigmoidæ˜¯å•è°ƒå‡½æ•°ï¼Œå¯ä»¥åœ¨logitç©ºé—´ç›´æ¥æ¯”è¾ƒ
            cls_max = np.max(cls_feat, axis=1)
            
            # è®¡ç®—é˜ˆå€¼å¯¹åº”çš„logitå€¼
            # sigmoid(x) > thresh  <==>  x > log(thresh / (1-thresh))
            thresh_logit = np.log(self.conf_thresh / (1 - self.conf_thresh))
            
            # ç­›é€‰é«˜ç½®ä¿¡åº¦å€™é€‰æ¡†
            valid_mask = cls_max > thresh_logit
            
            if not np.any(valid_mask):
                continue
            
            # åªå¯¹æœ‰æ•ˆå€™é€‰æ¡†è¿›è¡Œåç»­è®¡ç®—
            valid_bbox = bbox_feat[valid_mask]
            valid_cls = cls_feat[valid_mask]
            valid_grid = grid[valid_mask]
            
            # ====== ç±»åˆ«åˆ†æ•°è®¡ç®— ======
            # Sigmoidæ¿€æ´»
            scores = 1 / (1 + np.exp(-valid_cls))
            max_scores = np.max(scores, axis=1)
            max_classes = np.argmax(scores, axis=1)
            
            # ====== è¾¹ç•Œæ¡†è§£ç  ======
            # DFLè§£ç å¾—åˆ°ltrbè·ç¦»
            ltrb = self.dfl_decode(valid_bbox)
            
            # è®¡ç®—anchorä¸­å¿ƒç‚¹åæ ‡
            x_center = (valid_grid[:, 0] + 0.5) * stride
            y_center = (valid_grid[:, 1] + 0.5) * stride
            
            # ltrbè½¬xyxyï¼ˆå»é™¤paddingï¼Œè¿˜åŸåˆ°åŸå›¾å°ºåº¦ï¼‰
            x1 = (x_center - ltrb[:, 0] * stride - pad_left) / scale
            y1 = (y_center - ltrb[:, 1] * stride - pad_top) / scale
            x2 = (x_center + ltrb[:, 2] * stride - pad_left) / scale
            y2 = (y_center + ltrb[:, 3] * stride - pad_top) / scale
            
            # è£å‰ªåˆ°å›¾åƒè¾¹ç•Œ
            x1 = np.clip(x1, 0, orig_w)
            y1 = np.clip(y1, 0, orig_h)
            x2 = np.clip(x2, 0, orig_w)
            y2 = np.clip(y2, 0, orig_h)
            
            boxes = np.stack([x1, y1, x2, y2], axis=1)
            
            all_boxes.append(boxes)
            all_scores.append(max_scores)
            all_classes.append(max_classes)
        
        if not all_boxes:
            return np.array([]), np.array([]), np.array([])
        
        # ====== åˆå¹¶æ‰€æœ‰å°ºåº¦çš„æ£€æµ‹ç»“æœ ======
        boxes = np.concatenate(all_boxes, axis=0)
        scores = np.concatenate(all_scores, axis=0)
        classes = np.concatenate(all_classes, axis=0)
        
        # ====== NMSå»é‡ ======
        indices = cv2.dnn.NMSBoxes(
            boxes.tolist(),
            scores.tolist(),
            self.conf_thresh,
            self.nms_thresh
        )
        
        if len(indices) > 0:
            indices = indices.flatten()
            return boxes[indices], scores[indices], classes[indices]
        
        return np.array([]), np.array([]), np.array([])
    
    def draw(self, img, boxes, scores, classes):
        """
        åœ¨å›¾ç‰‡ä¸Šç»˜åˆ¶æ£€æµ‹ç»“æœ
        
        Args:
            img: è¾“å…¥å›¾ç‰‡
            boxes: æ£€æµ‹æ¡†
            scores: ç½®ä¿¡åº¦
            classes: ç±»åˆ«ID
        
        Returns:
            img: ç»˜åˆ¶åçš„å›¾ç‰‡
        """
        for box, score, cls in zip(boxes, scores, classes):
            x1, y1, x2, y2 = map(int, box)
            color = tuple(map(int, self.colors[int(cls)]))
            label = f"{self.class_names[int(cls)]}: {score:.2f}"
            
            # ç»˜åˆ¶è¾¹ç•Œæ¡†
            cv2.rectangle(img, (x1, y1), (x2, y2), color, 2)
            
            # ç»˜åˆ¶æ ‡ç­¾ï¼ˆå¸¦èƒŒæ™¯ï¼‰
            (label_w, label_h), _ = cv2.getTextSize(
                label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 2
            )
            cv2.rectangle(img, (x1, y1-label_h-10), (x1+label_w, y1), color, -1)
            cv2.putText(img, label, (x1, y1-5),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)
        
        return img


def main():
    """ä¸»å‡½æ•°ï¼šæ‘„åƒå¤´å®æ—¶æ£€æµ‹"""
    
    print("=" * 70)
    print("ğŸ¥ YOLOv11n æ‘„åƒå¤´å®æ—¶æ£€æµ‹")
    print("=" * 70)
    
    # åˆå§‹åŒ–æ£€æµ‹å™¨
    detector = YOLOv11Detector(
        model_path='/home/sunrise/RDK_infer/yolov11/yolov11_final.bin',
        conf_thresh=0.3,   # ç½®ä¿¡åº¦é˜ˆå€¼ï¼ˆå¯è°ƒæ•´ï¼‰
        nms_thresh=0.5,     # NMSé˜ˆå€¼ï¼ˆå¯è°ƒæ•´ï¼‰
        cls_num=80,  # ç±»åˆ«æ•°é‡
    )
    
    # æ‰“å¼€æ‘„åƒå¤´
    # USBæ‘„åƒå¤´ä½¿ç”¨0ï¼ŒMIPIæ‘„åƒå¤´ä½¿ç”¨8
    cap = cv2.VideoCapture(0)
    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
    
    if not cap.isOpened():
        print("âŒ æ— æ³•æ‰“å¼€æ‘„åƒå¤´")
        return
    
    print("\nğŸ“¹ æ‘„åƒå¤´å·²æ‰“å¼€ (640x480)")
    print("ğŸ¬ å¼€å§‹å®æ—¶æ£€æµ‹ (æŒ‰ 'q' é€€å‡º)")
    print("-" * 70)
    
    # è®¾ç½®æ˜¾ç¤ºæƒé™ï¼ˆé€šè¿‡SSHè¿è¡Œæ—¶éœ€è¦ï¼‰
    import os
    os.environ['DISPLAY'] = ':0'
    
    # FPSç»Ÿè®¡
    fps_list = []
    frame_count = 0
    
    try:
        while True:
            # è¯»å–å¸§
            ret, frame = cap.read()
            if not ret:
                print("âš ï¸  æ— æ³•è¯»å–æ‘„åƒå¤´å¸§")
                break
            
            # è®¡æ—¶å¼€å§‹
            start = time.time()
            
            # æ‰§è¡Œæ£€æµ‹
            boxes, scores, classes = detector.detect(frame)
            
            # ç»˜åˆ¶ç»“æœ
            result = detector.draw(frame.copy(), boxes, scores, classes)
            
            # è®¡ç®—FPS
            elapsed = time.time() - start
            fps = 1.0 / elapsed
            fps_list.append(fps)
            if len(fps_list) > 30:
                fps_list.pop(0)
            avg_fps = np.mean(fps_list)
            
            # åœ¨å›¾ç‰‡ä¸Šæ˜¾ç¤ºFPSå’Œæ£€æµ‹æ•°é‡
            cv2.putText(result, f"FPS: {avg_fps:.1f}", (10, 30),
                       cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
            cv2.putText(result, f"Objects: {len(boxes)}", (10, 70),
                       cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
            
            # æ˜¾ç¤ºç”»é¢ï¼ˆä¼šæ˜¾ç¤ºåœ¨HDMIæ˜¾ç¤ºå™¨ä¸Šï¼‰
            cv2.imshow('YOLOv11n Detection', result)
            
            # ç»ˆç«¯æ—¥å¿—
            frame_count += 1
            if frame_count % 30 == 0:
                print(f"å¸§: {frame_count:4d} | FPS: {avg_fps:5.1f} | æ£€æµ‹: {len(boxes):2d} ä¸ªç‰©ä½“")
            
            # æŒ‰'q'é€€å‡º
            if cv2.waitKey(1) & 0xFF == ord('q'):
                break
    
    except KeyboardInterrupt:
        print("\n\nâ¹ï¸  ç”¨æˆ·ä¸­æ–­ (Ctrl+C)")
    
    finally:
        # æ¸…ç†èµ„æº
        cap.release()
        cv2.destroyAllWindows()
        
        if len(fps_list) > 0:
            print("\n" + "=" * 70)
            print("ğŸ“Š æœ€ç»ˆç»Ÿè®¡")
            print("=" * 70)
            print(f"æ€»å¸§æ•°: {frame_count}")
            print(f"å¹³å‡FPS: {np.mean(fps_list):.1f}")
            print("=" * 70)
        
        print("\nâœ… ç¨‹åºç»“æŸ")


if __name__ == '__main__':
    main()